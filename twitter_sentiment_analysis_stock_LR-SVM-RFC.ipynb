{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "import datetime as dt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ta\n",
    "import tweepy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "from ta.utils import dropna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use: aapl,adbe,amzn,ctsh,fb,intc,msft,mu\n",
      "Ticker: msft\n"
     ]
    }
   ],
   "source": [
    "print('You can use: aapl,adbe,amzn,ctsh,fb,intc,msft,mu')\n",
    "\n",
    "ticker = input('Ticker: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentScore(Tweet):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    results = []\n",
    "    for sentence in Tweet:\n",
    "        vs = analyzer.polarity_scores(sentence)\n",
    "        results.append(vs)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price and Technical Indicator Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfStock(ticker,start,end):\n",
    "    df = web.DataReader(ticker.upper(),'yahoo',start,end)\n",
    "    data = ta.add_all_ta_features(df, \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", fillna=True).reset_index()\n",
    "    data = data[['Date','momentum_stoch','momentum_rsi','momentum_kama','trend_ema_fast','volume_vpt','Open','High','Low','Close','Volume','Adj Close']]\n",
    "    data['forecast'] = data['Adj Close'].shift(1)\n",
    "    data['Daily Return'] = (data['forecast'].pct_change())*100\n",
    "    data['target'] = int(False)\n",
    "    data.loc[data['Daily Return'] > 0, 'target']=int(True)\n",
    "    data = data.dropna() \n",
    "    data = data.set_index('Date')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainDf(ticker):\n",
    "    '''ticker inputs: aapl,adbe,amzn,ctsh,fb,intc,msft,mu: '''\n",
    "    df1 = pd.read_excel(ticker.lower()+'Tweets.xlsx')\n",
    "    df1['Tweet content']\n",
    "    df_history_results = pd.DataFrame(sentimentScore(df1['Tweet content']))\n",
    "    df_history_tweets = pd.merge(df1, df_history_results, left_index=True, right_index=True)\n",
    "    df_history_tweets = df_history_tweets[['Date','Followers','Tweet content','neg','neu','pos','compound']]\n",
    "    df_history_tweets['influenced'] = df_history_tweets['compound']*df_history_tweets['Followers']\n",
    "    negative = df_history_tweets.groupby('Date')['neg'].mean()\n",
    "    neutral = df_history_tweets.groupby('Date')['neu'].mean()\n",
    "    positive = df_history_tweets.groupby('Date')['pos'].mean()\n",
    "    compound = df_history_tweets.groupby('Date')['compound'].mean()\n",
    "    influenced = df_history_tweets.groupby('Date')['influenced'].mean()\n",
    "    dataframe = pd.DataFrame({'negative':negative, 'positive':positive, 'compound':compound, 'neutral':neutral, 'influenced':influenced})\n",
    "    main_df = pd.merge(dataframe, dfStock(ticker.upper(),'2016-03-31','2016-06-15'), left_index=True, right_index=True)\n",
    "    main_df = main_df.dropna()\n",
    "    main_df = main_df.reset_index()\n",
    "    main_df = main_df.drop(['Date','Daily Return','Adj Close','forecast','Open','Close','High','Low','Volume'], axis=1)\n",
    "    main_df = main_df.dropna()\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readying Data For Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = sklearn.model_selection.train_test_split(mainDf(ticker.upper()), test_size=0.2, random_state = 222)\n",
    "train,val = sklearn.model_selection.train_test_split(train, test_size=0.2, random_state = 222)\n",
    "trainy = train['target']\n",
    "del train['target']\n",
    "valy = val['target']\n",
    "del val['target']\n",
    "testy = test['target']\n",
    "del test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2222222222222222"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support Vector Machine \n",
    "from sklearn import svm\n",
    "model1 = sklearn.svm.SVC()\n",
    "model1.fit(train,trainy)\n",
    "model1.score(val,valy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2222222222222222"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model2 = sklearn.ensemble.RandomForestClassifier()\n",
    "model2.fit(train,trainy)\n",
    "model2.score(val,valy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model3 = sklearn.linear_model.LogisticRegression()\n",
    "model3.fit(train,trainy)\n",
    "model3.score(val,valy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5454545454545454\n",
      "0.9090909090909091\n",
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "#scores of each model (generally: higher the more accurate)\n",
    "mod1prob = model1.score(test,testy)\n",
    "mod2prob = model2.score(test,testy)\n",
    "mod3prob = model3.score(test,testy)\n",
    "print(model1.score(test,testy))\n",
    "print(model2.score(test,testy))\n",
    "print(model3.score(test,testy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Needed For Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction dataframe for part of the features \n",
    "pred = dfStock(ticker.upper(),dt.datetime.now() - dt.timedelta(days=365*15),dt.datetime.now())[['momentum_stoch','momentum_rsi','momentum_kama','trend_ema_fast','volume_vpt']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Twitter Sentiment Data For Stock Cashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are unique to your created application on twitter developer\n",
    "api_key = 'not shown for privacy protection'\n",
    "api_secret = 'not shown for privacy protection'\n",
    "access_token = 'not shown for privacy protection'\n",
    "access_secret = 'not shown for privacy protection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler( api_key,api_secret)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets(query):\n",
    "    df = pd.DataFrame()\n",
    "    data = []\n",
    "    for tweet in tweepy.Cursor(api.search, q=query, rpp=100, tweet_mode=\"extended\").items(1000): \n",
    "        date = tweet.created_at\n",
    "        text = tweet.full_text.encode('unicode-escape').decode('utf-8')\n",
    "        followers = tweet.user.followers_count              \n",
    "        data.append({'Tweet':text, 'Followers':followers, 'Date':date })\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.set_index('Followers')\n",
    "    df = df.sort_index(ascending = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tweets('$'+ticker.upper())\n",
    "df=df.reset_index()\n",
    "Tweet = df['Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(sentimentScore(Tweet))\n",
    "df_tweets = pd.merge(df, df_results, left_index=True, right_index=True)\n",
    "df_tweets = df_tweets[['Date','Followers','Tweet','neg','neu','pos','compound']]\n",
    "df_tweets['influenced'] = df_tweets['compound']*df_tweets['Followers']\n",
    "negative = df_tweets['neg'].mean()\n",
    "neutral = df_tweets['neu'].mean()\n",
    "positive = df_tweets['pos'].mean()\n",
    "compound = df_tweets['compound'].mean()\n",
    "influenced = df_tweets['influenced'].mean()\n",
    "df = pd.DataFrame({'negative':[negative], 'positive':[positive], 'compound':[compound], 'neutral':[neutral], 'influenced':[influenced]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = df[val.columns[0]].iloc[-1]\n",
    "p2 = df[val.columns[1]].iloc[-1]\n",
    "p3 = df[val.columns[2]].iloc[-1]\n",
    "p4 = df[val.columns[3]].iloc[-1]\n",
    "p5 = df[val.columns[4]].iloc[-1]\n",
    "p6 = pred[val.columns[5]].iloc[-1]\n",
    "p7 = pred[val.columns[6]].iloc[-1]\n",
    "p8 = pred[val.columns[7]].iloc[-1]\n",
    "p9 = pred[val.columns[8]].iloc[-1]\n",
    "p10 = pred[val.columns[9]].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSFT => Buy: There is a 90.91% confidence of having a positive daily return.\n"
     ]
    }
   ],
   "source": [
    "if mod1prob > mod2prob and mod1prob > mod3prob:\n",
    "    prediction = model1.predict([[p1,p2,p3,p4,p5,p6,p7,p8,p9,p10]])\n",
    "    if prediction == 1:\n",
    "        print(f'{ticker.upper()} => Buy: There is a {mod1prob.round(4)*100}% confidence of having a positive daily return.')\n",
    "    else:\n",
    "        print(f'{ticker.upper()} => Sell: There is a {mod1prob.round(4)*100}% confidence of having a negative daily return.')\n",
    "\n",
    "elif mod2prob > mod1prob and mod2prob > mod3prob:\n",
    "    prediction = model2.predict([[p1,p2,p3,p4,p5,p6,p7,p8,p9,p10]])\n",
    "    if prediction == 1:\n",
    "        print(f'{ticker.upper()} => Buy: There is a {mod2prob.round(4)*100}% confidence of having a positive daily return.')\n",
    "    else:\n",
    "        print(f'{ticker.upper()} => Sell: There is a {mod2prob.round(4)*100}% confidence of having a negative daily return.')\n",
    "\n",
    "else:\n",
    "    prediction = model3.predict([[p1,p2,p3,p4,p5,p6,p7,p8,p9,p10]])\n",
    "    if prediction == 1:\n",
    "        print(f'{ticker.upper()} => Buy: There is a {mod3prob.round(4)*100}% confidence of having a positive daily return.')\n",
    "    else:\n",
    "        print(f'{ticker.upper()} => Sell: There is a {mod3prob.round(4)*100}% confidence of having a negative daily return.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model score might be too high due to small amount of trainging and testing data\n",
    "#better results would result if a dataset became available with more than ~60 days of twitter data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

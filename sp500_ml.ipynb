{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas_datareader.data as web\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization, Concatenate\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with All Drivers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted stock price for SPY tomorrow is $372.0769348144531.\n",
      "Buy:  372.0769348144531 > 357.4599914550781 \n",
      "PCT DIFF:  4.0891131060220784 %\n"
     ]
    }
   ],
   "source": [
    "def data(ticker,start,end):\n",
    "    df = web.DataReader(ticker.upper(),'yahoo',start,end)[['Adj Close','High','Low']]\n",
    "    df['sm3'] = df['Adj Close'].rolling(window=3).mean() #3 day moving average\n",
    "    df['sm9'] = df['Adj Close'].rolling(window=9).mean() #9 day moving average\n",
    "    drivers = ['MSFT','AAPL','GOOG','GOOGL','AMZN','FB','^VIX'] #make a large portion of the etf's holdings\n",
    "    portfolio = pd.DataFrame() #create an emy dataframe to place data \n",
    "    failed = [] #empty list for failed queries\n",
    "    for stock in drivers: #for loop for all the features I want to try\n",
    "        try: #try clause just in case it failed\n",
    "            portfolio[stock] = web.DataReader(stock,'yahoo',start,end)['Adj Close'] #adj close of each feature\n",
    "            #moving averages to normalize the features\n",
    "            portfolio[f'{stock} sma3'] = portfolio[stock].rolling(window=3).mean() #moving averages as features\n",
    "            portfolio[f'{stock} sma9'] = portfolio[stock].rolling(window=9).mean()\n",
    "            portfolio = portfolio.drop([stock],axis=1) #drop the adj close price\n",
    "        except:\n",
    "            failed.append(stock) #add failed query ticker to list\n",
    "            print(f'{failed} was not properly calculated for. Are you sure this ticker is on an exchange?')\n",
    "    data = pd.concat([df,portfolio],axis = 1).dropna() #combine both dataframes\n",
    "    data['Target'] = data['Adj Close'].shift(-1) #shift adj close back 1: we are forecasting one day into the future\n",
    "    data = data.drop(['Adj Close','High','Low'],axis =1) #drop these bc nn works better \n",
    "    return data.dropna() #no null values\n",
    "\n",
    "\n",
    "\n",
    "def predict(df,pred_df):\n",
    "    X = df[df.columns] #feature data\n",
    "    del X['Target'] #don't want target variable in training data\n",
    "    Y = df[['Target']] #label data\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,random_state=50,test_size=0.2) #training and testing\n",
    "    x_val,x_test,y_val,y_test = train_test_split(x_test,y_test,random_state=50,test_size=0.5) #test and validation\n",
    "    model = Sequential() #basic sequential model \n",
    "    model.add(Dense(100, input_dim=x_train.shape[1], #need the input shape of the data in tensorflow 2x\n",
    "                        activation=tf.nn.leaky_relu, # was better than relu\n",
    "                        kernel_initializer='he_normal'))\n",
    "    model.add(Dense(75, input_dim=100, #100 'neurons' in the input layer\n",
    "                        activation=tf.nn.leaky_relu,\n",
    "                        kernel_initializer='he_normal'))\n",
    "    model.add(Dense(50, input_dim=75, #75 'neurons' in the first hidden layer\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer='he_normal'))\n",
    "    model.add(Dense(25, input_dim=50, #50 'neurons' in the second hidden layer\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer='he_normal'))\n",
    "    model.add(Dense(1, activation=tf.nn.leaky_relu, #only one answer so you need one 'neuron'\n",
    "                        kernel_initializer='he_normal'))\n",
    "    model.compile(loss='mean_squared_error', #mse loss function\n",
    "                      optimizer='adam', #adam optimizer\n",
    "                      metrics=['mape']) #mean absolute percentage error metric to determine the performance of the model\n",
    "    scaler = MinMaxScaler() #normalize the data since it is pretty different in terms of share price\n",
    "    x_train_scaled = scaler.fit_transform(x_train) #apply the normalizer to the training features\n",
    "    history = model.fit(x_train, y_train,  #fit the training data to the model\n",
    "                        validation_data=(x_val, y_val), #validation data to better see how the model is doing\n",
    "                        batch_size=32,\n",
    "                        epochs=10,\n",
    "                        verbose=0)\n",
    "    #pred_df = pred[features.columns]\n",
    "    pred_features = pred_df.iloc[-1] #these will be in the pred_data function \n",
    "    prediction = model.predict(np.array([pred_features])) #need it in numpy array \n",
    "    print(f'The predicted stock price for {ticker.upper()} tomorrow is ${float(prediction[0])}.')\n",
    "    if float(prediction[0])>float(df['Target'].iloc[-1:].values):\n",
    "        print('Buy: ', float(prediction[0]), '>',float(df['Target'].iloc[-1:].values),'\\nPCT DIFF: ',(float(prediction[0]) - float(df['Target'].iloc[-1:].values))/float(df['Target'].iloc[-1:].values)*100,'%',)\n",
    "    else:\n",
    "        print('Sell: ', float(prediction[0]), '<',float(df['Target'].iloc[-1:].values),'\\nPCT DIFF: ',(float(prediction[0]) - float(df['Target'].iloc[-1:].values))/float(df['Target'].iloc[-1:].values)*100,'%')\n",
    "\n",
    "\n",
    "\n",
    "def pred_data(ticker,start,end):\n",
    "    df = web.DataReader(ticker.upper(),'yahoo',start,end)[['Adj Close']] #query data of target security\n",
    "    df['sm3'] = df['Adj Close'].rolling(window=3).mean() #moving averages\n",
    "    df['sm9'] = df['Adj Close'].rolling(window=9).mean()\n",
    "    drivers = ['MSFT','AAPL','GOOG','GOOGL','AMZN','FB','^VIX'] #drivers \n",
    "    failed = []\n",
    "    portfolio = pd.DataFrame() #dataframe to add data to during the for loop\n",
    "    for stock in drivers: #for loop\n",
    "        try: #try clause\n",
    "            portfolio[stock] = web.DataReader(stock,'yahoo',start,end)['Adj Close']\n",
    "            portfolio[f'{stock} sma3'] = portfolio[stock].rolling(window=3).mean()\n",
    "            portfolio[f'{stock} sma9'] = portfolio[stock].rolling(window=9).mean()\n",
    "            portfolio = portfolio.drop([stock],axis=1) #drop adj close\n",
    "        except:\n",
    "            failed.append(stock) #add to failed list to see which ticker failed\n",
    "            print(f'{failed} was not properly calculated for. Are you sure this ticker is on an exchange?')\n",
    "    data = pd.concat([df,portfolio],axis = 1).dropna() #combine data lists\n",
    "    data = data.drop(['Adj Close'],axis = 1)\n",
    "    return data.dropna()\n",
    "\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    ticker = 'spy' #target security\n",
    "    start = dt.datetime.now() - dt.timedelta(days=365*5) #5 year time frame\n",
    "    end = dt.datetime.now() #today\n",
    "    predict(data(ticker,start,end),pred_data(ticker,start,end)) #calling the function we want to predict the target security"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Just Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 1s 14ms/step - loss: 34578.0473 - mape: 57.8134 - val_loss: 920.7321 - val_mape: 11.5423\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 445.5009 - mape: 7.2259 - val_loss: 64.7284 - val_mape: 2.7398\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 44.7541 - mape: 1.9697 - val_loss: 25.5212 - val_mape: 1.2413\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 33.2069 - mape: 1.4047 - val_loss: 25.2203 - val_mape: 1.2134\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 25.7674 - mape: 1.2849 - val_loss: 35.9312 - val_mape: 1.5912\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 29.0562 - mape: 1.4272 - val_loss: 25.9267 - val_mape: 1.2243\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 21.1162 - mape: 1.2041 - val_loss: 42.7701 - val_mape: 2.1150\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 41.9660 - mape: 1.8564 - val_loss: 24.1136 - val_mape: 1.1770\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 32.6816 - mape: 1.6354 - val_loss: 21.8014 - val_mape: 1.1223\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 20.6210 - mape: 1.1385 - val_loss: 24.0869 - val_mape: 1.1829\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 21.2644 - mape: 1.1159 - val_loss: 30.9738 - val_mape: 1.4865\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 27.1123 - mape: 1.4224 - val_loss: 20.6631 - val_mape: 1.1305\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 26.5256 - mape: 1.4166 - val_loss: 27.2328 - val_mape: 1.3475\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 26.7692 - mape: 1.2430 - val_loss: 20.7010 - val_mape: 1.1526\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 17.5311 - mape: 1.0747 - val_loss: 24.6887 - val_mape: 1.2477\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 24.6165 - mape: 1.3376 - val_loss: 65.8301 - val_mape: 2.8230\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 26.1300 - mape: 1.5231 - val_loss: 20.1663 - val_mape: 1.0348\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 14.3303 - mape: 0.9750 - val_loss: 19.8903 - val_mape: 1.0211\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 14.9491 - mape: 0.9786 - val_loss: 20.0605 - val_mape: 1.0233\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 17.6125 - mape: 1.1306 - val_loss: 21.6721 - val_mape: 1.0912\n",
      "The predicted stock price for SPY tomorrow is $359.0047302246094.\n",
      "Buy:  359.0047302246094 > 357.4599914550781 \n",
      "PCT DIFF:  0.43214312271514077 %\n"
     ]
    }
   ],
   "source": [
    "def data(ticker,start,end):\n",
    "    df = web.DataReader(ticker.upper(),'yahoo',start,end)[['Adj Close','High','Low']]\n",
    "    df['sm3'] = df['Adj Close'].rolling(window=3).mean() #3 day moving average\n",
    "    df['sm9'] = df['Adj Close'].rolling(window=9).mean() #9 day moving average\n",
    "    df['Target'] = df['Adj Close'].shift(-1) #shift adj close back 1: we are forecasting one day into the future\n",
    "    df = df.drop(['Adj Close','High','Low'],axis =1) #drop these bc nn works better \n",
    "    return df.dropna() #no null values\n",
    "\n",
    "\n",
    "\n",
    "def predict(df,pred_df):\n",
    "    X = df[df.columns] #feature data\n",
    "    del X['Target'] #don't want target variable in training data\n",
    "    Y = df[['Target']] #label data\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,random_state=50,test_size=0.2) #training and testing\n",
    "    x_val,x_test,y_val,y_test = train_test_split(x_test,y_test,random_state=50,test_size=0.5) #test and validation\n",
    "    model = Sequential() #basic sequential model \n",
    "    model.add(Dense(100, input_dim=x_train.shape[1], #need the input shape of the data in tensorflow 2x\n",
    "                        activation=tf.nn.leaky_relu, # was better than relu\n",
    "                        kernel_initializer='he_normal'))\n",
    "    model.add(Dense(75, input_dim=100, #100 'neurons' in the input layer\n",
    "                        activation=tf.nn.leaky_relu,\n",
    "                        kernel_initializer='he_normal'))\n",
    "    model.add(Dense(50, input_dim=75, #75 'neurons' in the first hidden layer\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer='he_normal'))\n",
    "    model.add(Dense(25, input_dim=50, #50 'neurons' in the second hidden layer\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer='he_normal'))\n",
    "    model.add(Dense(1, activation=tf.nn.leaky_relu, #only one answer so you need one 'neuron'\n",
    "                        kernel_initializer='he_normal'))\n",
    "    model.compile(loss='mean_squared_error', #mse loss function\n",
    "                      optimizer='adam', #adam optimizer\n",
    "                      metrics=['mape']) #mean absolute percentage error metric to determine the performance of the model\n",
    "    scaler = MinMaxScaler() #normalize the data since it is pretty different in terms of share price\n",
    "    x_train_scaled = scaler.fit_transform(x_train) #apply the normalizer to the training features\n",
    "    history = model.fit(x_train, y_train,  #fit the training data to the model\n",
    "                        validation_data=(x_val, y_val), #validation data to better see how the model is doing\n",
    "                        batch_size=32,\n",
    "                        epochs=20,\n",
    "                        verbose=1)\n",
    "    #pred_df = pred[features.columns]\n",
    "    pred_features = pred_df.iloc[-1] #these will be in the pred_data function \n",
    "    prediction = model.predict(np.array([pred_features])) #need it in numpy array \n",
    "    print(f'The predicted stock price for {ticker.upper()} tomorrow is ${float(prediction[0])}.')\n",
    "    if float(prediction[0])>float(df['Target'].iloc[-1:].values):\n",
    "        print('Buy: ', float(prediction[0]), '>',float(df['Target'].iloc[-1:].values),'\\nPCT DIFF: ',(float(prediction[0]) - float(df['Target'].iloc[-1:].values))/float(df['Target'].iloc[-1:].values)*100,'%',)\n",
    "    else:\n",
    "        print('Sell: ', float(prediction[0]), '<',float(df['Target'].iloc[-1:].values),'\\nPCT DIFF: ',(float(prediction[0]) - float(df['Target'].iloc[-1:].values))/float(df['Target'].iloc[-1:].values)*100,'%')\n",
    "\n",
    "\n",
    "\n",
    "def pred_data(ticker,start,end):\n",
    "    df = web.DataReader(ticker.upper(),'yahoo',start,end)[['Adj Close']] #query data of target security\n",
    "    df['sm3'] = df['Adj Close'].rolling(window=3).mean() #moving averages\n",
    "    df['sm9'] = df['Adj Close'].rolling(window=9).mean()\n",
    "    df = df.drop(['Adj Close'],axis = 1)\n",
    "    return df.dropna()\n",
    "\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    ticker = 'spy' #target security\n",
    "    start = dt.datetime.now() - dt.timedelta(days=365*5) #5 year time frame\n",
    "    end = dt.datetime.now() #today\n",
    "    predict(data(ticker,start,end),pred_data(ticker,start,end)) #calling the function we want to predict the target security"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Moving Averages and High / Low MA strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 1s 13ms/step - loss: 19381.1489 - mape: 38.0612 - val_loss: 232.8589 - val_mape: 5.9501\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 93.3479 - mape: 3.0675 - val_loss: 29.4498 - val_mape: 1.5425\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 31.6064 - mape: 1.5700 - val_loss: 36.4665 - val_mape: 1.8601\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 39.5925 - mape: 1.7356 - val_loss: 26.1298 - val_mape: 1.3861\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 25.1702 - mape: 1.3176 - val_loss: 25.9354 - val_mape: 1.3165\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 24.9681 - mape: 1.2241 - val_loss: 23.2974 - val_mape: 1.2053\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 19.0689 - mape: 1.1316 - val_loss: 23.7548 - val_mape: 1.3021\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 18.1419 - mape: 1.1224 - val_loss: 25.8061 - val_mape: 1.4164\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 21.1836 - mape: 1.2182 - val_loss: 21.6239 - val_mape: 1.1253\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 19.2639 - mape: 1.1647 - val_loss: 21.8005 - val_mape: 1.2084\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 15.6301 - mape: 1.0454 - val_loss: 21.4503 - val_mape: 1.0950\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 16.7830 - mape: 1.0149 - val_loss: 25.9696 - val_mape: 1.4837\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 24.5693 - mape: 1.3236 - val_loss: 20.6837 - val_mape: 1.1013\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 18.3743 - mape: 1.1123 - val_loss: 20.5014 - val_mape: 1.1081\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 16.8741 - mape: 1.0178 - val_loss: 20.4077 - val_mape: 1.1098\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 14.7630 - mape: 1.0276 - val_loss: 24.7329 - val_mape: 1.2339\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 18.2639 - mape: 1.1361 - val_loss: 20.1456 - val_mape: 1.0802\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 16.4755 - mape: 1.0079 - val_loss: 20.4258 - val_mape: 1.0466\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 20.0370 - mape: 1.1725 - val_loss: 20.0601 - val_mape: 1.0652\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 17.7772 - mape: 1.1096 - val_loss: 25.1442 - val_mape: 1.2913\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x104b76680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "The predicted stock price for SPY tomorrow is $359.84527587890625.\n",
      "Buy:  359.84527587890625 > 357.4599914550781 \n",
      "PCT DIFF:  0.6672871036891643 %\n"
     ]
    }
   ],
   "source": [
    "def data(ticker,start,end):\n",
    "    df = web.DataReader(ticker.upper(),'yahoo',start,end)[['Adj Close','High','Low']]\n",
    "    df['sm3'] = df['Adj Close'].rolling(window=3).mean() #3 day moving average\n",
    "    df['sm9'] = df['Adj Close'].rolling(window=9).mean() #9 day moving average\n",
    "    df['HighSM'] = df['High'].rolling(window=5).mean() #high moving average\n",
    "    df['LowSM'] = df['Low'].rolling(window=5).mean() #low moving average\n",
    "    df['Target'] = df['Adj Close'].shift(-1) #shift adj close back 1: we are forecasting one day into the future\n",
    "    df = df.drop(['Adj Close','High','Low'],axis =1) #drop these bc nn works better \n",
    "    return df.dropna() #no null values\n",
    "\n",
    "\n",
    "\n",
    "def predict(df,pred_df):\n",
    "    X = df[df.columns] #feature data\n",
    "    del X['Target'] #don't want target variable in training data\n",
    "    Y = df[['Target']] #label data\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,random_state=50,test_size=0.2) #training and testing\n",
    "    x_val,x_test,y_val,y_test = train_test_split(x_test,y_test,random_state=50,test_size=0.5) #test and validation\n",
    "    model = Sequential() #basic sequential model \n",
    "    model.add(Dense(100, input_dim=x_train.shape[1], #need the input shape of the data in tensorflow 2x\n",
    "                        activation=tf.nn.leaky_relu, # was better than relu\n",
    "                        kernel_initializer='he_normal'))\n",
    "    model.add(Dense(75, input_dim=100, #100 'neurons' in the input layer\n",
    "                        activation=tf.nn.leaky_relu,\n",
    "                        kernel_initializer='he_normal'))\n",
    "    model.add(Dense(50, input_dim=75, #75 'neurons' in the first hidden layer\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer='he_normal'))\n",
    "    model.add(Dense(25, input_dim=50, #50 'neurons' in the second hidden layer\n",
    "                    activation=tf.nn.leaky_relu,\n",
    "                    kernel_initializer='he_normal'))\n",
    "    model.add(Dense(1, activation=tf.nn.leaky_relu, #only one answer so you need one 'neuron'\n",
    "                        kernel_initializer='he_normal'))\n",
    "    model.compile(loss='mean_squared_error', #mse loss function\n",
    "                      optimizer='adam', #adam optimizer\n",
    "                      metrics=['mape']) #mean absolute percentage error metric to determine the performance of the model\n",
    "    scaler = MinMaxScaler() #normalize the data since it is pretty different in terms of share price\n",
    "    x_train_scaled = scaler.fit_transform(x_train) #apply the normalizer to the training features\n",
    "    history = model.fit(x_train, y_train,  #fit the training data to the model\n",
    "                        validation_data=(x_val, y_val), #validation data to better see how the model is doing\n",
    "                        batch_size=32,\n",
    "                        epochs=20,\n",
    "                        verbose=1)\n",
    "    #pred_df = pred[features.columns]\n",
    "    pred_features = pred_df.iloc[-1] #these will be in the pred_data function \n",
    "    prediction = model.predict(np.array([pred_features])) #need it in numpy array \n",
    "    print(f'The predicted stock price for {ticker.upper()} tomorrow is ${float(prediction[0])}.')\n",
    "    if float(prediction[0])>float(df['Target'].iloc[-1:].values):\n",
    "        print('Buy: ', float(prediction[0]), '>',float(df['Target'].iloc[-1:].values),'\\nPCT DIFF: ',(float(prediction[0]) - float(df['Target'].iloc[-1:].values))/float(df['Target'].iloc[-1:].values)*100,'%',)\n",
    "    else:\n",
    "        print('Sell: ', float(prediction[0]), '<',float(df['Target'].iloc[-1:].values),'\\nPCT DIFF: ',(float(prediction[0]) - float(df['Target'].iloc[-1:].values))/float(df['Target'].iloc[-1:].values)*100,'%')\n",
    "\n",
    "\n",
    "\n",
    "def pred_data(ticker,start,end):\n",
    "    df = web.DataReader(ticker.upper(),'yahoo',start,end)[['Adj Close','High','Low']] #query data of target security\n",
    "    df['sm3'] = df['Adj Close'].rolling(window=3).mean() #moving averages (3 day)\n",
    "    df['sm9'] = df['Adj Close'].rolling(window=9).mean() #moving averages (9 day)\n",
    "    df['HighSM'] = df['High'].rolling(window=5).mean() #high moving average\n",
    "    df['LowSM'] = df['Low'].rolling(window=5).mean() #low moving average\n",
    "    df = df.drop(['Adj Close','High','Low'],axis = 1)\n",
    "    return df.dropna()\n",
    "\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    ticker = 'spy' #target security\n",
    "    start = dt.datetime.now() - dt.timedelta(days=365*5) #5 year time frame\n",
    "    end = dt.datetime.now() #today\n",
    "    predict(data(ticker,start,end),pred_data(ticker,start,end)) #calling the function we want to predict the target security"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

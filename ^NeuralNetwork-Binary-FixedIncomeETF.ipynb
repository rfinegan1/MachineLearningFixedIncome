{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ta\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vanguard total bond market etf\n",
    "ticker = 'bnd'\n",
    "end = dt.datetime.now()\n",
    "start = end - dt.timedelta(days = 365*15)\n",
    "\n",
    "def taStock(ticker,start,end):\n",
    "    df = web.DataReader(ticker.upper(),'yahoo',start,end).reset_index()\n",
    "    data = ta.add_all_ta_features(df, \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", fillna=True)\n",
    "    data['Daily Return'] = (data['Adj Close'].pct_change())*100\n",
    "    data['target'] = int(False)\n",
    "    data.loc[data['Daily Return'] > 0, 'target']=int(True)\n",
    "    data = data.dropna() \n",
    "    return data\n",
    "\n",
    "data = taStock(ticker,start,end)\n",
    "data = data[['target','High','Low','Volume','volume_adi', 'volume_obv', 'volume_cmf', \n",
    "        'volume_fi', 'momentum_mfi','momentum_ao', 'momentum_kama', 'momentum_roc',\n",
    "        'volume_em', 'volume_sma_em', 'volume_vpt', 'volume_nvi', 'volume_vwap',\n",
    "        'volatility_atr', 'volatility_bbm', 'volatility_bbh', 'volatility_bbl',\n",
    "        'volatility_bbw', 'volatility_bbp', 'volatility_bbhi',\n",
    "        'volatility_bbli', 'volatility_kcc', 'volatility_kch', 'volatility_kcl',\n",
    "        'volatility_kcw', 'volatility_kcp', 'volatility_kchi',\n",
    "        'volatility_kcli', 'volatility_dcl', 'volatility_dch', 'trend_macd',\n",
    "        'trend_macd_signal', 'trend_macd_diff', 'trend_sma_fast',\n",
    "        'trend_sma_slow', 'trend_ema_fast', 'trend_ema_slow', 'trend_adx',\n",
    "        'trend_adx_pos', 'trend_adx_neg', 'trend_vortex_ind_pos',\n",
    "        'trend_vortex_ind_neg', 'trend_vortex_ind_diff', 'trend_trix',\n",
    "        'trend_mass_index', 'trend_cci', 'trend_dpo', 'trend_kst',\n",
    "        'trend_kst_sig', 'trend_kst_diff', 'trend_ichimoku_conv',\n",
    "        'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b',\n",
    "        'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'trend_aroon_up',\n",
    "        'trend_aroon_down', 'trend_aroon_ind', 'trend_psar_up',\n",
    "        'trend_psar_down', 'trend_psar_up_indicator',\n",
    "        'trend_psar_down_indicator', 'momentum_rsi', 'momentum_tsi',\n",
    "        'momentum_uo', 'momentum_stoch', 'momentum_stoch_signal', 'momentum_wr'\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data between training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8*len(data))\n",
    "features = data.drop(columns = ['target'])\n",
    "targets = data['target']\n",
    "X_train,X_test = features.values[:train_size,:],features.values[train_size:,:]\n",
    "y_train,y_test = targets.values[:train_size],targets.values[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build ANN Model, Compile, and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.067945643485212, 1: 0.94018296973962}\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 2672 samples, validate on 669 samples\n",
      "Epoch 1/10\n",
      "2672/2672 [==============================] - 2s 711us/sample - loss: 0.5851 - accuracy: 0.7133 - val_loss: 1884807.6076 - val_accuracy: 0.5486\n",
      "Epoch 2/10\n",
      "2672/2672 [==============================] - 1s 327us/sample - loss: 0.4698 - accuracy: 0.7713 - val_loss: 4190897.7347 - val_accuracy: 0.5486\n",
      "Epoch 3/10\n",
      "2672/2672 [==============================] - 1s 295us/sample - loss: 0.4255 - accuracy: 0.8016 - val_loss: 4546899.1248 - val_accuracy: 0.5486\n",
      "Epoch 4/10\n",
      "2672/2672 [==============================] - 1s 343us/sample - loss: 0.3858 - accuracy: 0.8234 - val_loss: 3342858.9634 - val_accuracy: 0.4514\n",
      "Epoch 5/10\n",
      "2672/2672 [==============================] - 1s 319us/sample - loss: 0.3907 - accuracy: 0.8249 - val_loss: 4102384.7272 - val_accuracy: 0.5486\n",
      "Epoch 6/10\n",
      "2672/2672 [==============================] - 1s 333us/sample - loss: 0.3707 - accuracy: 0.8204 - val_loss: 10330004.1375 - val_accuracy: 0.4514\n",
      "Epoch 7/10\n",
      "2672/2672 [==============================] - 1s 317us/sample - loss: 0.3578 - accuracy: 0.8353 - val_loss: 5141189.9641 - val_accuracy: 0.4514\n",
      "Epoch 8/10\n",
      "2672/2672 [==============================] - 1s 368us/sample - loss: 0.3343 - accuracy: 0.8522 - val_loss: 17478326.1943 - val_accuracy: 0.4514\n",
      "Epoch 9/10\n",
      "2672/2672 [==============================] - 1s 318us/sample - loss: 0.3357 - accuracy: 0.8499 - val_loss: 7201147.7549 - val_accuracy: 0.4514\n",
      "Epoch 10/10\n",
      "2672/2672 [==============================] - 1s 314us/sample - loss: 0.3333 - accuracy: 0.8443 - val_loss: 4484608.6278 - val_accuracy: 0.4514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10d733710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(1024,activation = tf.nn.leaky_relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512,activation = tf.nn.leaky_relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    #sigmoid is the best to use in the output layer for a binary classification artificial neural network\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "#class weights => these are needed for a stock that historically is known for a linear upward trend\n",
    "up = len(y_train[y_train>0])\n",
    "down = len(y_train)-up\n",
    "total = len(y_train)\n",
    "weight_for_up = total / (2*up)\n",
    "weight_for_down = total / (2*down)\n",
    "class_weight = {0:weight_for_down, 1:weight_for_up}\n",
    "print(class_weight)\n",
    "\n",
    "# Compile with optimizer, loss fxn, and metric (accuracy is good for classification models)\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#preprocessing \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# Fitting to the training set\n",
    "model.fit(X_train_scaled,y_train,class_weight=class_weight,batch_size=32,epochs=10,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/669 [==============================] - 0s 341us/sample - loss: 1.0418 - accuracy: 0.8117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0417886093949345, 0.8116592]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
